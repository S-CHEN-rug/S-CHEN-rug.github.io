
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Shuyi Chen | Voice Technology</title>
  <script>
    function toggleLanguage() {
      document.body.classList.toggle('lang-zh');
    }
  </script>
</head>
<body>
  <header style="overflow: auto;">
    
    <h1>Shuyi Chen / é™ˆå§ä¼Š</h1>
    <p>MSc Voice Technology | University of Groningen</p>
    <button onclick="toggleLanguage()">ğŸŒ Switch Language / åˆ‡æ¢è¯­è¨€</button>
  </header>

  <nav>
    <a href="#about">About / å…³äº</a>
    <a href="#project">Project / é¡¹ç›®</a>
    <a href="#contact">Contact / è”ç³»</a>
  </nav>

  <main>
    <section id="about">
      <h2>About Me / å…³äºæˆ‘</h2>
      <p class="en">I am a Master's student in Voice Technology at the University of Groningen, focusing on expressive and controllable Text-to-Speech systems.</p>
      <p class="zh">æˆ‘æ˜¯åœ¨æ ¼ç½—å®æ ¹å¤§å­¦æ”»è¯»è¯­éŸ³æŠ€æœ¯ç¡•å£«çš„å­¦ç”Ÿï¼Œç ”ç©¶æ–¹å‘ä¸ºå¯æ§ä¸å…·è¡¨ç°åŠ›çš„è¯­éŸ³åˆæˆç³»ç»Ÿã€‚</p>
    </section>

    <section id="project">
      <h2>Current Project / å½“å‰é¡¹ç›®</h2>
      <h3>Enhancing Surprise Perception in TTS through Keyword-Level Prosody Control</h3>
      <p class="en">This project proposes a prosody control framework to enhance surprise in synthesized speech using FastSpeech2 and HiFi-GAN.</p>
      <p class="zh">æœ¬é¡¹ç›®æå‡ºä¸€ç§èŠ‚å¥æ§åˆ¶æ¡†æ¶ï¼Œé€šè¿‡åœ¨å…³é”®è¯å¤„è°ƒèŠ‚éŸ³é«˜ä¸èƒ½é‡å¢å¼ºè¯­éŸ³åˆæˆä¸­çš„â€œæƒŠè®¶â€æ„ŸçŸ¥ã€‚</p>
      <p><a href="your-thesis-pdf-link.pdf" target="_blank">ğŸ“„ Download Thesis / ä¸‹è½½è®ºæ–‡ (PDF)</a></p>
      <p><a href="https://github.com/S-CHEN-rug" target="_blank">ğŸ”— GitHub Repository / é¡¹ç›®ä»£ç </a></p>
    </section>

    <section id="contact">
      <h2>Contact / è”ç³»æ–¹å¼</h2>
      <p>Email: <a href="mailto:s.chen@student.rug.nl">s.chen.66@student.rug.nl</a></p>
      <p>GitHub: <a href="https://github.com/S-CHEN-rug" target="_blank">S-CHEN-rug</a></p>
    </section>

<div style="text-align:right; margin-bottom:1em;">
  <label for="langToggle">ğŸŒ Language:</label>
  <select id="langToggle" onchange="toggleLang()">
    <option value="en">English</option>
    <option value="zh">ä¸­æ–‡</option>
  </select>
</div>
<script>
  function toggleLang() {
    var lang = document.getElementById("langToggle").value;
    document.querySelectorAll('.en').forEach(el => el.style.display = lang === 'en' ? 'block' : 'none');
    document.querySelectorAll('.zh').forEach(el => el.style.display = lang === 'zh' ? 'block' : 'none');
  }
  window.onload = toggleLang;
</script>

<div style="text-align:right; margin-bottom:1em;">
  <label for="langToggle">ğŸŒ Language:</label>
  <select id="langToggle" onchange="toggleLang()">
    <option value="en">English</option>
    <option value="zh">ä¸­æ–‡</option>
  </select>
</div>
<script>
  function toggleLang() {
    var lang = document.getElementById("langToggle").value;
    document.querySelectorAll('.en').forEach(el => el.style.display = lang === 'en' ? 'block' : 'none');
    document.querySelectorAll('.zh').forEach(el => el.style.display = lang === 'zh' ? 'block' : 'none');
  }
  window.onload = toggleLang;
</script>

<section id="overview">
  <h2>Overview / é¡¹ç›®æ¦‚è¿°</h2>
  <div class="en">
    <p>This project investigates whether keyword-level pitch and energy control can enhance the perception of the emotion "surprise" in neural TTS systems.
    A multilingual FastSpeech2-based TTS system is built and evaluated across two languages (Mandarin and English).</p>
  </div>
  <div class="zh">
    <p>æœ¬é¡¹ç›®æ¢ç´¢æ˜¯å¦å¯ä»¥é€šè¿‡å¯¹å…³é”®è¯çš„éŸ³é«˜å’Œèƒ½é‡æ§åˆ¶æ¥å¢å¼ºç¥ç» TTS ç³»ç»Ÿä¸­â€œæƒŠè®¶â€æƒ…ç»ªçš„æ„ŸçŸ¥æ•ˆæœã€‚
    å®éªŒç³»ç»ŸåŸºäº FastSpeech2 æ¨¡å‹ï¼Œè·¨è¯­è¨€ï¼ˆä¸­æ–‡å’Œè‹±æ–‡ï¼‰è¿›è¡Œæ„å»ºä¸è¯„ä¼°ã€‚</p>
  </div>
</section>

<section id="methodology">
  <h2>Methodology / æ–¹æ³•è®¾è®¡</h2>
  <div class="en">
    <p>The study uses keyword pitch/energy scaling during inference without modifying the core architecture of FastSpeech2.
    Surprise keywords were extracted using a GPT-based API, with prosody control applied via the variance adaptor.
    In addition, several implementation improvements were made:</p>
    <ul>
      <li>Emotion keyword detection and tagging</li>
      <li>Emotion type and intensity parameterization</li>
      <li>Smooth transition at keyword regions</li>
      <li>Batch structure updated to support keyword info</li>
      <li>Integration of smoothing in synthesis</li>
      <li>1D convolution smoothing on mel-spectrogram</li>
      <li>Integration of keyword smoothing in synth_samples</li>
    </ul>
  </div>
  <div class="zh">
    <p>æœ¬ç ”ç©¶åœ¨ä¸æ›´æ”¹ FastSpeech2 æ¨¡å‹ä¸»ç»“æ„çš„å‰æä¸‹ï¼Œåœ¨æ¨ç†é˜¶æ®µå¯¹å…³é”®è¯è¿›è¡ŒéŸ³é«˜ä¸èƒ½é‡å¢å¼ºæ§åˆ¶ã€‚
    æƒŠè®¶å…³é”®è¯ç”± GPT æ¥å£è¯†åˆ«ï¼Œå¹¶é€šè¿‡ variance adaptor å®ç°éŸµå¾‹æ§åˆ¶ã€‚åŒæ—¶ï¼Œæœ¬ç ”ç©¶è¿›è¡Œäº†ä»¥ä¸‹æ”¹è¿›ï¼š</p>
    <ul>
      <li>æƒ…ç»ªå…³é”®è¯è¯†åˆ«ä¸æ ‡æ³¨</li>
      <li>æƒ…ç»ªç±»åˆ«ä¸å¼ºåº¦å‚æ•°åŒ–</li>
      <li>å…³é”®è¯åŒºåŸŸçš„è¿‡æ¸¡å¹³æ»‘æ§åˆ¶</li>
      <li>æ‰¹æ¬¡ç»“æ„æ›´æ–°ä»¥æ”¯æŒå…³é”®è¯æ ‡æ³¨</li>
      <li>åœ¨åˆæˆé˜¶æ®µé›†æˆå¹³æ»‘æ§åˆ¶</li>
      <li>å¯¹æ¢…å°”è°±å›¾è¿›è¡Œä¸€ç»´å·ç§¯å¹³æ»‘</li>
      <li>åœ¨ synth_samples ä¸­é›†æˆå…³é”®è¯å¹³æ»‘ä¿¡æ¯</li>
    </ul>
  </div>
</section>

<section id="results">
  <h2>Results / å®éªŒç»“æœ</h2>
  <div class="en">
    <p>Results from both forced-choice and scalar rating tests show that keyword-level control increases surprise perception significantly compared to baseline synthesis.
    Cross-linguistic generalizability is demonstrated, though language-specific tuning is needed.</p>
  </div>
  <div class="zh">
    <p>å¼ºåˆ¶é€‰æ‹©ä¸è¿ç»­è¯„åˆ†æµ‹è¯•å‡è¡¨æ˜ï¼Œå…³é”®è¯æ§åˆ¶æ˜¾è‘—å¢å¼ºäº†â€œæƒŠè®¶â€æƒ…ç»ªçš„æ„ŸçŸ¥æ•ˆæœã€‚
    è¯¥æ–¹æ³•åœ¨ä¸­è‹±æ–‡ä¸­å‡æ˜¾ç¤ºè‰¯å¥½æ³›åŒ–æ€§ï¼Œä½†éœ€è¿›è¡Œè¯­è¨€ç‰¹å®šå‚æ•°å¾®è°ƒã€‚</p>
  </div>
</section>

<section id="demo">
  <h2>Audio Demonstration Table / éŸ³é¢‘æ¼”ç¤ºè¡¨æ ¼</h2>
  <table border="1" cellspacing="0" cellpadding="10" style="border-collapse: collapse; width: 100%; text-align: center;">
    <thead style="background-color: #990000; color: white;">
      <tr>
        <th>Example / ç±»å‹</th>
        <th>Baseline</th>
        <th>Mild</th>
        <th>Moderate</th>
        <th>Strong</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>ä¸­æ–‡ç”·å£° - ä¾‹å¥1</td>
        <td><audio controls src="audio/zh_m_01_baseline.mp3"></audio></td>
        <td><audio controls src="audio/zh_m_01_mild.mp3"></audio></td>
        <td><audio controls src="audio/zh_m_01_moderate.mp3"></audio></td>
        <td><audio controls src="audio/zh_m_01_strong.mp3"></audio></td>
      </tr>
      <tr><td>ä¸­æ–‡ç”·å£° - ä¾‹å¥2</td>
        <td><audio controls src="audio/zh_m_02_baseline.mp3"></audio></td>
        <td><audio controls src="audio/zh_m_02_mild.mp3"></audio></td>
        <td><audio controls src="audio/zh_m_02_moderate.mp3"></audio></td>
        <td><audio controls src="audio/zh_m_02_strong.mp3"></audio></td>
      </tr>
      <tr><td>ä¸­æ–‡å¥³å£° - ä¾‹å¥1</td>
        <td><audio controls src="audio/zh_f_01_baseline.mp3"></audio></td>
        <td><audio controls src="audio/zh_f_01_mild.mp3"></audio></td>
        <td><audio controls src="audio/zh_f_01_moderate.mp3"></audio></td>
        <td><audio controls src="audio/zh_f_01_strong.mp3"></audio></td>
      </tr>
      <tr><td>ä¸­æ–‡å¥³å£° - ä¾‹å¥2</td>
        <td><audio controls src="audio/zh_f_02_baseline.mp3"></audio></td>
        <td><audio controls src="audio/zh_f_02_mild.mp3"></audio></td>
        <td><audio controls src="audio/zh_f_02_moderate.mp3"></audio></td>
        <td><audio controls src="audio/zh_f_02_strong.mp3"></audio></td>
      </tr>
      <tr><td>English Male - Sentence 1</td>
        <td><audio controls src="audio/en_m_01_baseline.mp3"></audio></td>
        <td><audio controls src="audio/en_m_01_mild.mp3"></audio></td>
        <td><audio controls src="audio/en_m_01_moderate.mp3"></audio></td>
        <td><audio controls src="audio/en_m_01_strong.mp3"></audio></td>
      </tr>
      <tr><td>English Male - Sentence 2</td>
        <td><audio controls src="audio/en_m_02_baseline.mp3"></audio></td>
        <td><audio controls src="audio/en_m_02_mild.mp3"></audio></td>
        <td><audio controls src="audio/en_m_02_moderate.mp3"></audio></td>
        <td><audio controls src="audio/en_m_02_strong.mp3"></audio></td>
      </tr>
      <tr><td>English Female - Sentence 1</td>
        <td><audio controls src="audio/en_f_01_baseline.mp3"></audio></td>
        <td><audio controls src="audio/en_f_01_mild.mp3"></audio></td>
        <td><audio controls src="audio/en_f_01_moderate.mp3"></audio></td>
        <td><audio controls src="audio/en_f_01_strong.mp3"></audio></td>
      </tr>
      <tr><td>English Female - Sentence 2</td>
        <td><audio controls src="audio/en_f_02_baseline.mp3"></audio></td>
        <td><audio controls src="audio/en_f_02_mild.mp3"></audio></td>
        <td><audio controls src="audio/en_f_02_moderate.mp3"></audio></td>
        <td><audio controls src="audio/en_f_02_strong.mp3"></audio></td>
      </tr>
    </tbody>
  </table>
</section>

</main>

  <footer>
    <p>&copy; 2025 Shuyi Chen. All rights reserved.</p>
  </footer>

  <style>
    body { font-family: Arial, sans-serif; margin: 0; padding: 0; background: white; color: black; }
    header { background-color: #990000; color: white; padding: 2rem 1rem; text-align: center; }
    nav { background: #000; display: flex; justify-content: center; gap: 1rem; padding: 0.5rem; }
    nav a { color: white; text-decoration: none; padding: 0.5rem; }
    nav a:hover { background: #990000; }
    main { padding: 2rem; max-width: 900px; margin: auto; }
    section { margin-bottom: 2rem; }
    footer { background: #f1f1f1; text-align: center; padding: 1rem; font-size: 0.9rem; }
    .zh { display: none; }
    .lang-zh .en { display: none; }
    .lang-zh .zh { display: block; }
    button { margin-top: 1rem; padding: 0.5rem 1rem; background: #000; color: #fff; border: none; cursor: pointer; }
    button:hover { background: #990000; }
    
  </style>
</body>
</html>
