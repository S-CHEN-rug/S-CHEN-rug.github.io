<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Shuyi Chen | Voice Technology</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <h1>Shuyi Chen</h1>
    <p>MSc Voice Technology | University of Groningen</p>
  </header>

  <nav>
    <a href="#about">About</a>
    <a href="#project">Project</a>
    <a href="#publications">Publications</a>
    <a href="#contact">Contact</a>
  </nav>

  <main>
    <section id="about">
      <h2>About Me</h2>
      <p>I am a Master's student in Voice Technology at the University of Groningen, with a research focus on expressive and controllable Text-to-Speech (TTS) systems. My work explores keyword-level prosody control for enhancing emotion perception in synthesized speech.</p>
    </section>

    <section id="project">
      <h2>Current Project</h2>
      <h3>Enhancing Surprise Perception in TTS through Keyword-Level Prosody Control</h3>
      <p>This project proposes a lightweight and interpretable prosody control framework to enhance surprise perception in speech synthesis. It utilizes FastSpeech2 and HiFi-GAN, with localized pitch and energy modulation on semantically salient keywords.</p>
      <p><a href="your-thesis-pdf-link.pdf" target="_blank">ðŸ“„ Download Thesis (PDF)</a></p>
      <p><a href="https://github.com/S-CHEN-rug" target="_blank">ðŸ”— View Code on GitHub</a></p>
    </section>

    <section id="publications">
      <h2>Publications</h2>
      <ul>
        <li><strong>Chen, S.</strong> (2025). <em>Enhancing Surprise Perception in TTS through Keyword-Level Prosody Control</em>. Master's Thesis, University of Groningen.</li>
      </ul>
    </section>

    <section id="contact">
      <h2>Contact</h2>
      <p>Email: <a href="mailto:s.chen@student.rug.nl">s.chen@student.rug.nl</a></p>
      <p>GitHub: <a href="https://github.com/S-CHEN-rug" target="_blank">S-CHEN-rug</a></p>
    </section>
  </main>

  <footer>
    <p>&copy; 2025 Shuyi Chen. All rights reserved.</p>
  </footer>
</body>
</html>
